---
title: What is the AI Subnet?
icon: microchip-ai
iconType: regular
---

<Warning>**Notice:** The Livepeer AI Video Subnet is currently in its **Alpha** phase. During this early stage, you may encounter various bugs or issues. Should you discover any problems, please report them via our [issue tracker](https://github.com/livepeer/go-livepeer/issues/new/choose) on GitHub. We appreciate your patience and feedback as we work to improve the AI Subnet. Your contributions are vital to our progress, and we look forward to seeing what you'll create!</Warning>

The **AI Subnet** is the newest addition to the Livepeer ecosystem, first outlined in [this SPE treasury proposal](https://explorer.livepeer.org/treasury/82843445347363563575858115586375001878287509193479217286690041153234635982713). This cutting-edge platform provides a **decentralized**, **open-source** framework for a broad array of Generative AI inference tasks, including image and video generation and upscaling, all within the Livepeer network. Leveraging Livepeer's decentralized protocol, the AI Subnet offers accessible, cost-effective generative AI capabilities, empowering developers and creators worldwide to incorporate advanced AI tools into their projects.

### Currently available Pipelines

The AI Subnet currently supports the following generative AI pipelines:

- **text-to-image**: Convert text descriptions into images.
- **image-to-image**: Transform images from one style to another.
- **image-super-resolution**: Enhance image quality by upscaling resolution.

For more information on these pipelines, and the Diffusion models suported in these pipelines, refer to the [AI Subnet Pipelines](/ai/pipelines) page.

### Advantages of Livepeer's AI Subnet

- **Decentralization**: The AI Subnet operates on a decentralized network, ensuring that AI tasks are processed securely and efficiently.
- **Cost-Effective**: By leveraging the Livepeer network, the AI Subnet offers cost-effective AI inference capabilities compared to traditional cloud-based solutions.
- **Scalability**: The AI Subnet is designed to scale with demand, allowing for the addition of new Orchestrators and Gateways as needed.
- **Open-Source**: The AI Subnet is built on open-source technology, enabling developers to contribute to its ongoing development and improvement.

### Terminology

- **Mainnet Transcoding Network**: This network comprises Orchestrators and Gateways that perform or coordinate transcoding tasks on the mainnet.
- **AI Subnet**: A specialized subnet of the Livepeer network, consisting of AI Orchestrators and AI Gateways, engineered specifically for managing AI inference tasks on the mainnet.
- **Mainnet Transcoding Network Orchestrator**: A node that handles transcoding tasks within the _Mainnet Transcoding Network_. For simplicity, it's often referred to as _Orchestrator_ throughout the rest of the documentation.
- **Mainnet Transcoding Network Gateway**: A node that routes transcoding tasks to the correct Orchestrators for processing on the _Mainnet Transcoding Network_. For simplicity, it's often referred to as _Gateway_ throughout the rest of the documentation.
- **AI Orchestrator**: A specialized node tasked with carrying out AI inference operations on the _AI Subnet_.
- **AI Gateway**: A specialized node that routes AI tasks to the correct AI Orchestrators for processing on the _AI Subnet_.

### How does it Work?

The AI Subnet is built on top of the existing Livepeer network, leveraging the same core infrastructure to facilitate AI inference tasks. The AI Orchestrator nodes are responsible for executing AI tasks, while the AI Gateway nodes manage the routing of these tasks to the appropriate Orchestrators. The AI Subnet is designed to be scalable, enabling the addition of new Orchestrators and Gateways as needed to accommodate growing demand.

### Present Constraints

- **Alpha Phase**: The AI Subnet is currently in its Alpha phase, and users may encounter bugs or issues during this early stage.
- **Supports Lited Set of Models**: The AI Subnet currently supports a limited set of AI models. This range is however slowely expanding with the aim to support any custom model in the future.
- **Only Higher VRAM GPUs Supported**: Currently the AI Subnet requires GPUs with at least 16GB of VRAM to run AI inference tasks effectively. We are working to expand this support to lower VRAM GPUs in the future.

### Kickstart Your Journey


<CardGroup cols={2}>
  <Card
    href="/ai/orchestrator/get_started"
    title="Setup AI Orchestrator"
    icon="robot"
  >
    Setup your AI Orchestrator and earn fees from AI tasks.
  </Card>
  <Card
    href="/ai/setup-gateway"
    title="Setup AI Gateway"
    icon="play"
  >
    Establish an AI Gateway to serve a broad customer base with AI tasks.
  </Card>
  <Card
    href="/ai/builders"
    title="Build your dApp"
    icon="screwdriver-wrench"
  >
    Develop your innovative dApp on the AI Subnet efficiently and at scale.
  </Card>
  <Card
    href="/ai/api-reference"
    title="AI API Reference"
    icon="rectangle-terminal"
  >
    Explore the AI Subnet API to integrate AI capabilities into your projects.
  </Card>
</CardGroup>
